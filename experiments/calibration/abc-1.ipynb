{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABC with the OpenCL RAMP model\n",
    "\n",
    "Multi-paramter calibration of the RAMP model using Approximate Bayesian Computation.\n",
    "\n",
    "Calibrates on the individual hazard multipliers:\n",
    " - current_risk_beta\n",
    " - presymptomatic\n",
    " - asymptomatic\n",
    " - symptomatic\n",
    " \n",
    "For a full list of parameters used in the model, see the default parameters file '[default.yml](../../model_parameters/default.yml)'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about libraries:\n",
    "\n",
    " - Use [pyabc](https://pyabc.readthedocs.io/) (listed in [pythonMCMC](https://gabriel-p.github.io/pythonMCMC/)).\n",
    "\n",
    "Note about installing. It is annoying. I did: \n",
    "```\n",
    "conda install mpi4py\n",
    "pip install pyabc\n",
    "```\n",
    "but also had to follow the first proposed solution [here](https://github.com/ipython/ipyparallel/issues/349) (reinstall setuptools and numpy).\n",
    "\n",
    "Then I got a really annoying error about \"`ValueError: Cell is empty`\" which happened to be a pickle problem and was resolved by installing older versions: `cloudpickle==1.4.1 distributed==2.17.0` as per [this post](https://stackoverflow.com/questions/63497235/airflow-scheduler-crashes-when-a-dag-is-run)\n",
    "\n",
    " - Also adapted Josie's notebook: https://github.com/Urban-Analytics/uncertainty/blob/master/hm_abc_simple_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import yaml # pyyaml library for reading the parameters.yml file\n",
    "import os\n",
    "import pandas as pd\n",
    "import unittest\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import pyabc\n",
    "from pygam import LinearGAM  # For graphing posteriors\n",
    "from pyabc.transition.multivariatenormal import MultivariateNormalTransition  # For drawing from the posterior\n",
    "\n",
    "from microsim.opencl.ramp.run import run_headless\n",
    "from microsim.opencl.ramp.snapshot_convertor import SnapshotConvertor\n",
    "from microsim.opencl.ramp.snapshot import Snapshot\n",
    "from microsim.opencl.ramp.params import Params, IndividualHazardMultipliers, LocationHazardMultipliers\n",
    "from microsim.opencl.ramp.simulator import Simulator\n",
    "from microsim.opencl.ramp.disease_statuses import DiseaseStatus\n",
    "\n",
    "# Quieten down the pyopencl info messages (just print errors)\n",
    "import logging\n",
    "logging.getLogger(\"pyopencl\").setLevel(logging.ERROR)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "#import experiments_functions  # For the ones outside the class\n",
    "from opencl_runner import OpenCLRunner # Some additional notebook-specific functions required (functions.py)\n",
    "\n",
    "# Set this to False to recalculate all results (good on HPC or whatever). \n",
    "# If true then it loads pre-calculated results from pickle files (much quicker)\n",
    "LOAD_PICKLES = False\n",
    "\n",
    "# Useful for connecting to this kernel\n",
    "#%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/fbenitez/Documents/ResearchATI/RAMP-UA/experiments/calibration',\n",
       " '/Users/fbenitez/opt/anaconda3/envs/ramp-ua/lib/python37.zip',\n",
       " '/Users/fbenitez/opt/anaconda3/envs/ramp-ua/lib/python3.7',\n",
       " '/Users/fbenitez/opt/anaconda3/envs/ramp-ua/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Users/fbenitez/opt/anaconda3/envs/ramp-ua/lib/python3.7/site-packages',\n",
       " '/Users/fbenitez/opt/anaconda3/envs/ramp-ua/lib/python3.7/site-packages/RAMP_UA-1.4.0.dev0-py3.7.egg',\n",
       " '/Users/fbenitez/opt/anaconda3/envs/ramp-ua/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/fbenitez/.ipython',\n",
       " '..',\n",
       " '..']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get default params for all runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the parameters file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the parameters for the OpenCL model. (See [main.py](https://github.com/Urban-Analytics/RAMP-UA/blob/052861cc51be5bc1827c85bb827209f0df73c685/microsim/main.py#L262) for an example of how this is done in the code). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/fbenitez/Documents/ResearchATI/RAMP-UA/experiments/calibration'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS_FILE = os.path.join(\"../../\",\"model_parameters\", \"default.yml\")\n",
    "PARAMS = OpenCLRunner.create_parameters(parameters_file=PARAMETERS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../model_parameters/default.yml'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMETERS_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get snapshot path\n",
    "**NB** this is the path to the OpenCL snapshot file generated by running `microsim/main.py`. You need to initilaise the model at least once to create the snapshot. The following says 'run in opencl mode and stop once initialisation has finished':\n",
    "\n",
    "```\n",
    "python microsim/main.py -ocl -init\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENCL_DIR = \"../../microsim/opencl\"\n",
    "SNAPSHOT_FILEPATH = os.path.join(OPENCL_DIR, \"snapshots\", \"cache.npz\")\n",
    "assert os.path.isfile(SNAPSHOT_FILEPATH), f\"Snapshot doesn't exist: {SNAPSHOT_FILEPATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation Data\n",
    "\n",
    "Read the real observations (number of hospital admissions in Devon) that will be used to calibrate the model. See the [README](./observation_data/README.md) for information about how these observations were obtained. They aren't the raw cases, it's actually a model that was fitted to the lagged cases. They need to be made cumulative as this is how they will be compared to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 16371\n"
     ]
    }
   ],
   "source": [
    "# New per day:\n",
    "gam_cases = pd.read_csv(os.path.join(\"../../\", \"gam_cases.csv\"), header=0, names=[\"Day\", \"Cases\"], )\n",
    "\n",
    "# Cumulative\n",
    "OBSERVATIONS = pd.DataFrame( {\"Day\": gam_cases['Day'], \"Cases\": gam_cases.cumsum()['Cases']} )\n",
    "\n",
    "assert OBSERVATIONS.tail(1)['Cases'].values[0] == sum(gam_cases['Cases'])\n",
    "print(f\"Total cases: {sum(gam_cases['Cases'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run default (manually calibrated) model\n",
    "\n",
    "This shows what happens with the 'default' (manually calibrated) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 5  # Number of iterations to run for\n",
    "NUM_SEED_DAYS = 10  # Number of days to seed the population\n",
    "USE_GPU = True\n",
    "STORE_DETAILED_COUNTS = False\n",
    "REPETITIONS = 2\n",
    "USE_HEALTHIER_POP=False # I dont know the impact of having this parameter, but as it is bolean I set it as False.\n",
    "\n",
    "assert ITERATIONS < len(OBSERVATIONS), \\\n",
    "    f\"Have more iterations ({ITERATIONS}) than observations ({len(OBSERVATIONS)}).\"\n",
    "\n",
    "# Initialise the class so that its ready to run the model.\n",
    "# This isn't actually necessary immediately as the `run_opencl_model_multi` function is a static method\n",
    "# so doesn't read any of the class parameters, but the init is necessary\n",
    "# for calibration later when some parameters can't be passed to the run function directly\n",
    "OpenCLRunner.init(\n",
    "    iterations = ITERATIONS, \n",
    "    repetitions = REPETITIONS, \n",
    "    observations = OBSERVATIONS,\n",
    "    use_gpu = USE_GPU,\n",
    "    store_detailed_counts = STORE_DETAILED_COUNTS, \n",
    "    parameters_file = PARAMETERS_FILE, \n",
    "    opencl_dir = OPENCL_DIR,\n",
    "    use_healthier_pop = USE_HEALTHIER_POP,\n",
    "    snapshot_filepath = SNAPSHOT_FILEPATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running models:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing obesity arrays not equal\n",
      "0.6317622812303595\n",
      "0.6317622812303595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running models:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "clBuildProgram failed: BUILD_PROGRAM_FAILURE - clBuildProgram failed: BUILD_PROGRAM_FAILURE - clBuildProgram failed: BUILD_PROGRAM_FAILURE\n\nBuild on <pyopencl.Device 'Intel(R) UHD Graphics 630' on 'Apple' at 0x7f80da627b00>:\n\n<program source>:1:10: fatal error: 'prng.cl' file not found\n#include \"prng.cl\"\n         ^\n===========================================================================\nBuild on <pyopencl.Device 'AMD Radeon Pro 5500M Compute Engine' on 'Apple' at 0x7f80da627b20>:\n\n<program source>:3:10: fatal error: 'prng.cl' file not found\n#include \"prng.cl\"\n         ^\n\n(options: -I ../../microsim/opencl/ramp/kernels/ -I /Users/fbenitez/opt/anaconda3/envs/ramp-ua/lib/python3.7/site-packages/pyopencl/cl)\n(source saved as /var/folders/n8/gpdfd81x2xqg81bv12th7p840000gr/T/tmpjxx_v68n.cl)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n8/gpdfd81x2xqg81bv12th7p840000gr/T/ipykernel_30840/518107697.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mOpenCLRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepetitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Temporarily use more repetitions to give a good baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mOpenCLRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_detailed_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Temporarily output age breakdowns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mfitness0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_params0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummaries0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenCLRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model_with_params_abc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_full_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mOpenCLRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepetitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREPETITIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mOpenCLRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_detailed_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTORE_DETAILED_COUNTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ResearchATI/RAMP-UA/experiments/opencl_runner.py\u001b[0m in \u001b[0;36mrun_model_with_params_abc\u001b[0;34m(cls, input_params_dict, return_full_details)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mrepetitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREPETITIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mopencl_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPENCL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSNAPSHOT_FILEPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSE_GPU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             \u001b[0mstore_detailed_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTORE_DETAILED_COUNTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         )\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ResearchATI/RAMP-UA/experiments/opencl_runner.py\u001b[0m in \u001b[0;36mrun_opencl_model_multi\u001b[0;34m(repetitions, iterations, params, use_gpu, use_healthier_pop, store_detailed_counts, opencl_dir, snapshot_filepath, multiprocess, random_ids)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;31m# Return as a list to force the models to execute (otherwise this is delayed because starmap returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;31m# a generator. Also means we can use tqdm to get a progress bar, which is nice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mto_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Running models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepetitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".. finished, took {round(float(time.time() - start_time), 2)}s)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ResearchATI/RAMP-UA/experiments/opencl_runner.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;31m# Return as a list to force the models to execute (otherwise this is delayed because starmap returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;31m# a generator. Also means we can use tqdm to get a progress bar, which is nice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mto_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Running models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepetitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".. finished, took {round(float(time.time() - start_time), 2)}s)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ramp-ua/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ResearchATI/RAMP-UA/experiments/opencl_runner.py\u001b[0m in \u001b[0;36mrun_opencl_model\u001b[0;34m(i, iterations, snapshot_filepath, params, opencl_dir, use_gpu, use_healthier_pop, store_detailed_counts, quiet)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# Create a simulator and upload the snapshot data to the OpenCL device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0msimulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnapshot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopencl_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopencl_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnapshot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ramp-ua/lib/python3.7/site-packages/RAMP_UA-1.4.0.dev0-py3.7.egg/microsim/opencl/ramp/simulator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, snapshot, gpu, opencl_dir, num_seed_days)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ramp_ua.cl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mprogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mprogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"-I {kernel_dir}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         kernels = Kernels(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ramp-ua/lib/python3.7/site-packages/pyopencl/__init__.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, options, devices, cache_dir)\u001b[0m\n\u001b[1;32m    524\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                         cache_dir=cache_dir, include_path=include_path),\n\u001b[0;32m--> 526\u001b[0;31m                     options_bytes=options_bytes, source=self._source)\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwas_cached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ramp-ua/lib/python3.7/site-packages/pyopencl/__init__.py\u001b[0m in \u001b[0;36m_build_and_catch_errors\u001b[0;34m(self, build_func, options_bytes, source)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Python 3.2 outputs the whole list of currently active exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# This serves to remove one (redundant) level from that nesting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;31m# }}}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: clBuildProgram failed: BUILD_PROGRAM_FAILURE - clBuildProgram failed: BUILD_PROGRAM_FAILURE - clBuildProgram failed: BUILD_PROGRAM_FAILURE\n\nBuild on <pyopencl.Device 'Intel(R) UHD Graphics 630' on 'Apple' at 0x7f80da627b00>:\n\n<program source>:1:10: fatal error: 'prng.cl' file not found\n#include \"prng.cl\"\n         ^\n===========================================================================\nBuild on <pyopencl.Device 'AMD Radeon Pro 5500M Compute Engine' on 'Apple' at 0x7f80da627b20>:\n\n<program source>:3:10: fatal error: 'prng.cl' file not found\n#include \"prng.cl\"\n         ^\n\n(options: -I ../../microsim/opencl/ramp/kernels/ -I /Users/fbenitez/opt/anaconda3/envs/ramp-ua/lib/python3.7/site-packages/pyopencl/cl)\n(source saved as /var/folders/n8/gpdfd81x2xqg81bv12th7p840000gr/T/tmpjxx_v68n.cl)"
     ]
    }
   ],
   "source": [
    "OpenCLRunner.update(repetitions=3)  # Temporarily use more repetitions to give a good baseline\n",
    "OpenCLRunner.update(store_detailed_counts=True)  # Temporarily output age breakdowns\n",
    "(fitness0, sim0, obs0, out_params0, summaries0) = OpenCLRunner.run_model_with_params_abc({}, return_full_details=True)\n",
    "OpenCLRunner.update(repetitions=REPETITIONS)\n",
    "OpenCLRunner.update(store_detailed_counts=STORE_DETAILED_COUNTS)\n",
    "\n",
    "# Check the model returns the observations correctly\n",
    "np.array_equal(obs0, OBSERVATIONS.loc[:len(sim0)-1,\"Cases\"])\n",
    "\n",
    "# Print the fitness and plot the different disease counts\n",
    "print(f\"fitness: {fitness0}\")\n",
    "#print(pd.DataFrame({\"sim\":sim, \"real_obs1\":obs}))\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "x = range(len(sim0))\n",
    "ax.plot(x, OpenCLRunner.get_cumulative_new_infections(summaries0), label=\"sim\")\n",
    "ax.plot(x, obs0, label=\"obs\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot output summary data\n",
    "\n",
    "#### Total counts of disease status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summaries(summaries, observations=None, plot_type=\"error_bars\"):\n",
    "\n",
    "    #fig, ax = plt.subplots(1, len(DiseaseStatus), sharey=True)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,7))\n",
    "    \n",
    "    # Work out the number of repetitions and iterations\n",
    "    iters, reps = _get_iters_and_reps(summaries)\n",
    "    x = range(iters)\n",
    "    total_not_susceptible = np.zeros(iters)  # Used to compare to observations\n",
    "    \n",
    "    for d, disease_status in enumerate(DiseaseStatus):\n",
    "\n",
    "        # Calculate the mean and standard deviation\n",
    "        mean, sd = OpenCLRunner.get_mean_total_counts(summaries, d, get_sd=True)\n",
    "        \n",
    "        # Don't plot susceptible or recovered as it hides everytihng else\n",
    "        if disease_status==DiseaseStatus.Susceptible or disease_status==DiseaseStatus.Recovered:\n",
    "            continue\n",
    "        \n",
    "        if plot_type == \"error_bars\":\n",
    "            ax.errorbar(x, mean, sd, label=f\"{disease_status}\" )\n",
    "        elif plot_type == \"lines\":\n",
    "            for rep in range(reps):\n",
    "                ax.plot(x, matrix[rep], label=f\"{disease_status} {rep}\", \n",
    "                        color=plt.cm.get_cmap(\"hsv\", len(DiseaseStatus))(d) )\n",
    "\n",
    "    if observations is not None:\n",
    "        # Plot the observations (cumulative infections)\n",
    "        ax.plot(x, observations.loc[:len(x)-1, \"Cases\"], \n",
    "                label=f\"Observations (cumulative cases)\", color=\"black\", linestyle=\"dashed\")\n",
    "        # And the total new infections, for comparison\n",
    "        ax.plot(x, OpenCLRunner.get_cumulative_new_infections(summaries),\n",
    "               label=f\"Total not susceptible \", color=\"grey\", linestyle=\"dashed\")\n",
    "        \n",
    "    \n",
    "    ax.legend() \n",
    "    ax.set_title(\"Disease Status\")\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Number of cases\")\n",
    "    #ax.set_ylim(0, 5000)\n",
    "    #ax.set_xlim(0,30)\n",
    "\n",
    "def _get_iters_and_reps(summaries):\n",
    "    reps = len(summaries)\n",
    "    iters = len(summaries[0].total_counts[0])\n",
    "    return (iters, reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summaries(summaries=summaries0, observations=OBSERVATIONS, plot_type=\"error_bars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_summaries(summaries=summaries0, plot_type=\"lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disease statuses by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_disease_status_by_age(summaries):\n",
    "\n",
    "    #fig, ax = plt.subplots(1, len(DiseaseStatus), sharey=True)\n",
    "    fig, ax = plt.subplots(int(len(DiseaseStatus)/2), int(len(DiseaseStatus)/2), \n",
    "                           figsize=(15,11), tight_layout=True)\n",
    "    iters, reps = _get_iters_and_reps(summaries)\n",
    "    x = range(iters)\n",
    "    age_thresholds = summaries[0].age_thresholds\n",
    "\n",
    "    for d, disease_status in enumerate(DiseaseStatus):\n",
    "        lower_age_bound = 0\n",
    "        for age_idx in range(len(age_thresholds)):\n",
    "            matrix = np.zeros(shape=(reps, iters))\n",
    "            for rep in range(reps):\n",
    "                #matrix[age_idx][rep][it] = summaries[rep].age_counts[str(disease_status)][age_idx][it]\n",
    "                matrix[rep] = summaries[rep].age_counts[str(disease_status)][age_idx]\n",
    "            mean = np.mean(matrix, axis=0)\n",
    "            sd = np.std(matrix, axis=0)\n",
    "            ax.flat[d].errorbar(x, mean, sd, label=f\"{lower_age_bound} - {age_thresholds[age_idx]}\" )\n",
    "            lower_age_bound = age_thresholds[age_idx]\n",
    "                \n",
    "            ax.flat[d].legend() \n",
    "            ax.flat[d].set_title(f\"{str(disease_status)}\")\n",
    "            ax.flat[d].set_xlabel(\"Iteration\")\n",
    "            ax.flat[d].set_ylabel(\"Number of cases\")\n",
    "    #fig.set_title(f\"Num {disease_status} people by age group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_disease_status_by_age(summaries0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MSOA geodata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load MSOA shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsim.load_msoa_locations import load_osm_shapefile, load_msoa_shapes\n",
    "\n",
    "data_dir = (\"../../devon_data\")\n",
    "\n",
    "osm_buildings = load_osm_shapefile(data_dir)\n",
    "\n",
    "devon_msoa_shapes = load_msoa_shapes(data_dir, visualize=False)\n",
    "\n",
    "devon_msoa_shapes.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot disease status by MSOA for a given timestep and status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_msoa_choropleth(msoa_shapes, summary, disease_status, timestep, ax=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Summary can be a single summary, or a list of a few summaries (will need an average)\n",
    "    # get dataframes for all statuses\n",
    "    msoa_data = summary.get_area_dataframes()\n",
    "    \n",
    "    msoa_data_for_status = msoa_data[disease_status]\n",
    "\n",
    "    # add \"Code\" column so dataframes can be merged\n",
    "    msoa_data_for_status[\"Code\"] = msoa_data_for_status.index\n",
    "    msoa_shapes = pd.merge(msoa_shapes, msoa_data_for_status, on=\"Code\")\n",
    "\n",
    "    msoa_shapes.plot(column=f\"Day{timestep}\", legend=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_status = \"exposed\"\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=int(REPETITIONS/2) if (REPETITIONS % 2) == 0 else int(REPETITIONS/2)+1, \n",
    "                         figsize=(12,6))\n",
    "\n",
    "for i in range(REPETITIONS):\n",
    "    ax = axes.flat[i]\n",
    "    plot_msoa_choropleth(devon_msoa_shapes,  summaries0[i], \n",
    "                         disease_status, 99, ax=ax )\n",
    "#plot_msoa_choropleth(devon_msoa_shapes, summaries0[0], disease_status, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Bayesian Computation\n",
    "\n",
    " - Use [pyabc](https://pyabc.readthedocs.io/) (listed in [pythonMCMC](https://gabriel-p.github.io/pythonMCMC/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need a new distance function that extracts the data from dataframes.\n",
    "def distance(sim,obs):\n",
    "    fit = OpenCLRunner.fit_l2(sim[\"data\"],obs[\"data\"])\n",
    "    print(fit)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Error: Fitness Function\n",
    "\n",
    "To calibrate the model we need a fitness function that tells us, for a given result, how similar it is to the observations. The 'observations' (in the [gam_cases.csv](../../gam_cases.csv)) are the number of new infections per day. The model equivalent of this is to look at the number of non-susceptible people per day (i.e. add up all the _non-susceptible_ disease statuses).\n",
    "\n",
    "Ultimately two arrays showing the cumulative infections per day need to be compared. There are lots of ways to do this. For now, just take the **Euclidean distance (L2 norm)** between the observed number of cases and the simulated number of cases.\n",
    "\n",
    "This is implemented in `opencl_runner.OpenCLRunner.fit_l2` (see [opencl_runner.py](../opencl_runner.py)).\n",
    "\n",
    "Note that the model is seeded using the first few days of cases, so at the beginning of a run the simulated data will be identical to the observations. This doesn't matter though because the relative difference between different parameter combinations will be the same regardless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priors\n",
    "\n",
    "Define the priors. This time make them all normal distributions, but will decorate them later to make sure they are positive. (_For some reason there is an error thrown if they are decorated first_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_risk_beta_rv = pyabc.RV(\"norm\", 0.05, 0.5)\n",
    "presymptomatic_rv = pyabc.RV(\"norm\", 0.5, 0.5)\n",
    "asymptomatic_rv = pyabc.RV(\"norm\", 0.5, 0.5)\n",
    "symptomatic_rv = pyabc.RV(\"norm\", 0.5, 0.5)\n",
    "\n",
    "# Note, could create the distribution here (currently done below), then plot the priors directly using, e.g. \n",
    "#   y= p riors['current_risk_beta_prior'].pdf(x)\n",
    "# but for some reason decorating them with the LowerBoundDecorator breaks the call to pdf()\n",
    "\n",
    "x = np.linspace(-0 ,5, 150)\n",
    "lines = plt.plot(x, pyabc.Distribution(param=current_risk_beta_rv).pdf({\"param\": x}),\n",
    "                 label = \"current_risk_beta\", lw = 3)\n",
    "lines = plt.plot(x, pyabc.Distribution(param=presymptomatic_rv).pdf({\"param\": x}),\n",
    "                 label = \"presymptomatic_prior\", lw = 3)\n",
    "lines = plt.plot(x, pyabc.Distribution(param=asymptomatic_rv).pdf({\"param\": x}),\n",
    "                 label = \"asymptomatic_prior\", lw = 3)\n",
    "lines = plt.plot(x, pyabc.Distribution(param=symptomatic_rv).pdf({\"param\": x}),\n",
    "                 label = \"symptomatic_prior\", lw = 3)\n",
    "\n",
    "plt.autoscale(tight=True)\n",
    "\n",
    "plt.axvline(x=0.5, ls='--', color=\"black\", label=\"x=1\")\n",
    "plt.title(\"Priors\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(title=r\"$\\alpha$ parameter\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorate the RVs so that they wont go below 0 and create the prior distribution \n",
    "\n",
    "priors = pyabc.Distribution(\n",
    "    current_risk_beta = pyabc.LowerBoundDecorator(current_risk_beta_rv, 0.0),\n",
    "    presymptomatic = pyabc.LowerBoundDecorator(presymptomatic_rv, 0.0),\n",
    "    asymptomatic = pyabc.LowerBoundDecorator(asymptomatic_rv, 0.0),\n",
    "    symptomatic = pyabc.LowerBoundDecorator(symptomatic_rv, 0.0)\n",
    "    )\n",
    "\n",
    "#current_risk_beta_prior = pyabc.LowerBoundDecorator(current_risk_beta_prior, 0.0)\n",
    "#presymptomatic_prior = pyabc.LowerBoundDecorator(presymptomatic_prior, 0.0)\n",
    "#asymptomatic_prior = pyabc.LowerBoundDecorator(asymptomatic_prior, 0.0)\n",
    "#symptomatic_prior = pyabc.LowerBoundDecorator(symptomatic_prior, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the ABC algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = pyabc.ABCSMC(\n",
    "    models=OpenCLRunner.run_model_with_params_abc, # Model (could be a list)\n",
    "    parameter_priors=priors, # Priors (could be a list)\n",
    "    distance_function=distance,  # Distance function\n",
    "    sampler = pyabc.sampler.SingleCoreSampler()  # Single core because the model is parallelised\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Real' cumulative cases: \n",
    "y_observed = OBSERVATIONS.loc[:ITERATIONS-1, \"Cases\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where to store results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = (\"sqlite:///\" + os.path.join(\".\", \"abc-2.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = abc.new(db_path, {\"data\": y_observed})  # (ID only matters if multiple runs stored is same DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = None\n",
    "fname = \"./abc-1.pkl\"\n",
    "\n",
    "if LOAD_PICKLES:\n",
    "    with open( fname, \"rb\" ) as f:\n",
    "        history = pickle.load(f)\n",
    "else:\n",
    "    #history = abc.run(minimum_epsilon=.1, max_nr_populations=10)\n",
    "    history = abc.run(max_nr_populations=5) \n",
    "    # The history object only works if it has the associated database too ('abc-1.db')\n",
    "    with open( fname, \"wb\" ) as f:\n",
    "        pickle.dump( history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, arr_ax = plt.subplots(2, 2)\n",
    "\n",
    "pyabc.visualization.plot_sample_numbers(history, ax=arr_ax[0][0])\n",
    "pyabc.visualization.plot_epsilons(history, ax=arr_ax[0][1])\n",
    "#pyabc.visualization.plot_credible_intervals(\n",
    "#    history, levels=[0.95, 0.9, 0.5], ts=[0, 1, 2, 3, 4],\n",
    "#    show_mean=True, show_kde_max_1d=True,\n",
    "#    refval={'mean': 2.5}, \n",
    "#    arr_ax=arr_ax[1][0])\n",
    "pyabc.visualization.plot_effective_sample_sizes(history, ax=arr_ax[1][1])\n",
    "\n",
    "plt.gcf().set_size_inches((12, 8))\n",
    "plt.gcf().tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the marginal posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,int(len(priors)/2), figsize=(12,8))\n",
    "\n",
    "#cmap = { 0:'k',1:'b',2:'y',3:'g',4:'r' }  # Do this automatically for len(params)\n",
    "\n",
    "for i, param in enumerate(priors.keys()):\n",
    "    ax = axes.flat[i]\n",
    "    for t in range(history.max_t + 1):\n",
    "        df, w = history.get_distribution(m=0, t=t)\n",
    "        pyabc.visualization.plot_kde_1d(df, w, x=param, ax=ax, \n",
    "            label=f\"{param} PDF t={t}\", \n",
    "            alpha=1.0 if t==0 else float(t)/history.max_t, # Make earlier populations transparent\n",
    "            color= \"black\" if t==history.max_t else None # Make the last one black\n",
    "        ) \n",
    "        ax.legend()\n",
    "        #ax.axvline(x=posterior_df.loc[1,param], color=\"grey\", linestyle=\"dashed\")\n",
    "        #ax.set_title(f\"{param}: {posterior_df.loc[0,param]}\")\n",
    "        ax.set_title(f\"{param}\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As above, but this time do a separate plot for each population\n",
    "\n",
    "#fig, axes = plt.subplots(3,int(history.max_t/2), figsize=(10,8))\n",
    "#for t in range(history.max_t + 1):\n",
    "#    ax = axes.flat[t]\n",
    "#    for i, param in enumerate(priors.keys()):\n",
    "#        df, w = history.get_distribution(m=0, t=t)\n",
    "#        pyabc.visualization.plot_kde_1d(df, w, x=param, ax=ax, \n",
    "#            label=f\"{param}\")\n",
    "#    ax.legend()\n",
    "#    ax.set_title(f\"t={t}\")\n",
    "# fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the 2D correlations (_I'm not sure how to read this_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyabc.visualization.plot_histogram_matrix(history, size=(12,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the posterior\n",
    "\n",
    "Have a look at the posterior distribution for the final population. This is made up of the posterior estimates for each particle in the popualtion and the associated weight.\n",
    "\n",
    "_Note about the distrubtion returned by `get_distribution`_: With each iteration, the algorithm decreases epsilon. So in the end all particles should be within some small distance, epsilon, of the observations. However, within this range, the particles will be randomly distributed. The weight of the particle is a function of the prior and of the number of other particles that are close by, so we wouldn't necessarily expect that particles with high weight should have better fitness than those of low weight. It's just looking at the wrong thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df, _w = history.get_distribution(m=0, t=history.max_t)\n",
    "# Merge dataframe and weights and sort by weight (highest weight at the top)\n",
    "_df['weight'] = _w\n",
    "posterior_df = _df.sort_values('weight', ascending=False).reset_index()\n",
    "posterior_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code shows how to calculate the fitness associated with each particle (not the correct way to draw from the posterior so not especially useful)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_fitnesses = []\n",
    "for i, row in posterior_df.iterrows():\n",
    "    param_values = { param:row[str(param)] for param in priors}\n",
    "    (_fitness, _sim, _obs, _out_params, _summaries) = \\\n",
    "          OpenCLRunner.run_model_with_params_abc(param_values, return_full_details=True)\n",
    "    df_fitnesses.append(_fitness)\n",
    "    print(f\"{i}, Fitness: {_fitness}\")\n",
    "posterior_df['fitness'] = df_fitnesses"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(range(len(posterior_df)), posterior_df['fitness'])\n",
    "plt.xlabel(\"Particle number\")\n",
    "plt.ylabel(\"Fitness\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(range(len(posterior_df)), posterior_df['weight'])\n",
    "plt.xlabel(\"Particle number\")\n",
    "plt.ylabel(\"Weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a posterior over the parameters. There are two ways to find the 'optimal' model:\n",
    "\n",
    " - Find the posterior mode (i.e. the set of parameters that gave the result that was the most likely to have generated the observations). This is useful because then the 'optimal' parameters can be reported and these can be set as the default for future model runs (i.e. a traditional calibration).\n",
    " \n",
    " - Sample from the posterior distribution N times (N=100?) to generate a posterior over the model outputs. This better captures the uncertainty in the parameter values and in the associated model outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ABC Posterior (A) - Sample\n",
    "\n",
    "Sample from the distribution of parameter posteriors to generate a distribution over the mode likely model results. Use kernel density approximation to randomly draw some equally weighted samples.\n",
    "\n",
    "(This is kind of pointless as we already know what the parameter posteriors are, but we could use this mechanism to make predictions from the model)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This old (incorrect?) code shows how to sample manually using the weights. It has subsequently been replaced by KDE\n",
    "\n",
    "\n",
    "# Can optionally attach weights and sort (good for debugging)\n",
    "#df['weight'] = w\n",
    "#df = df.sort_values('weight', ascending=False)\n",
    "\n",
    "# Reset the index so that rows count from 0\n",
    "df = df.reset_index()  \n",
    "\n",
    "# Temporarlly reverse weights to see what happens\n",
    "#w = (1-w) / sum(1-w)\n",
    "\n",
    "# Create a list with row numbers to sample from the dataframe\n",
    "sample_idx = np.random.choice(\n",
    "            a=range(history.get_nr_particles_per_population().values[-1]),\n",
    "            size=N_samples, replace=True, p=w)\n",
    "\n",
    "for idx in sample_idx:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samples = 100\n",
    "df, w = history.get_distribution(m=0, t=history.max_t)\n",
    "\n",
    "# Sample from the dataframe of posteriors using KDE\n",
    "kde = MultivariateNormalTransition(scaling=1)\n",
    "kde.fit(df, w)\n",
    "samples = kde.rvs(N_samples)\n",
    "\n",
    "## Instead sample just using the weights (this isn't the best way to do it though, should use KDE)\n",
    "#df = df.reset_index()  # So that the row index is 0-N (currently it's something else)\n",
    "#sample_idx = np.random.choice(\n",
    "#            a=range(history.get_nr_particles_per_population().values[-1]),\n",
    "#            size=N_samples, replace=True, p=w)\n",
    "#samples = df.iloc[sample_idx] \n",
    "\n",
    "# Now run N models and store the results of each one\n",
    "fitness_l = []  # Fitness values for each sample (model)\n",
    "sim_l = []  # The full simulation results\n",
    "obs_l = []  # Observations (should be the same for each sample)\n",
    "out_params_l = []  # The parameters objects used in each sample (all parameters in the model)\n",
    "out_calibrated_params_l = []  # The values of the specific calibrated parameters for the sample\n",
    "summaries_l = []  # The summaries objects\n",
    "\n",
    "for i, sample in samples.iterrows():\n",
    "\n",
    "    # Check for negatives. If needed, resample\n",
    "    while (sample < 0).values.any():\n",
    "        print(\"Found negatives. Resampling\")\n",
    "        sample = kde.rvs()\n",
    "        \n",
    "    # Create a dictionary with the parameters and their values for this sample\n",
    "    param_values = { param:sample[str(param)] for param in priors}\n",
    "    \n",
    "    # Run the model\n",
    "    (_fitness, _sim, _obs, _out_params, _summaries) = \\\n",
    "          OpenCLRunner.run_model_with_params_abc(param_values, return_full_details=True)\n",
    "    print(f\"Fitness: {_fitness}.\")\n",
    "    #print(f\"Fitness: {_fitness}. Sample: {sample}\")\n",
    "    \n",
    "    fitness_l.append(_fitness)\n",
    "    sim_l.append(_sim)\n",
    "    obs_l.append(_obs)\n",
    "    out_params_l.append(_out_params)\n",
    "    out_calibrated_params_l.append(param_values)\n",
    "    summaries_l.append(_summaries)\n",
    "\n",
    "# Sanity check\n",
    "for i in range(len(obs_l)-1):\n",
    "    assert np.array_equal(obs_l[0], obs_l[i])\n",
    "    \n",
    "# Save these because it took ages to sample\n",
    "def pickle_samples(mode, *arrays):\n",
    "    if mode==\"save\":\n",
    "        with open(\"abc-1-samples.pkl\", \"wb\") as f:\n",
    "            for x in arrays:\n",
    "                pickle.dump(x, f)\n",
    "        return\n",
    "    elif mode==\"load\":\n",
    "        with open(\"abc-1-samples.pkl\", \"rb\") as f:\n",
    "            fitness_l = pickle.load(f)\n",
    "            sim_l = pickle.load(f)\n",
    "            obs_l = pickle.load(f)\n",
    "            out_params_l = pickle.load(f)\n",
    "            out_calibrated_params_l = pickle.load(f)\n",
    "            summaries_l = pickle.load(f)\n",
    "        return( fitness_l, sim_l, obs_l, out_params_l, out_calibrated_params_l, summaries_l)\n",
    "    else:\n",
    "        raise Exception(f\"Unkonwn mode: {mode}\")\n",
    "pickle_samples('save', fitness_l, sim_l, obs_l, out_params_l, out_calibrated_params_l, summaries_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the individual results for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Original fitness: {round(fitness0)}\\nOptimised fitness: {round(fitness)}\")\n",
    "\n",
    "# Normalise fitness to 0-1 to calculate transparency\n",
    "_fitness = np.array(fitness_l)  # Easier to do maths on np.array\n",
    "fitness_norm = (_fitness-min(_fitness))/(max(_fitness)-min(_fitness))\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "x = range(len(sim_l[0]))\n",
    "for i in range(len(summaries_l)):\n",
    "    ax.plot(x, OpenCLRunner.get_cumulative_new_infections(summaries_l[i]),\n",
    "            #label=f\"Particle {df.index[sample_idx[i]]}\", \n",
    "            color=\"black\", alpha = 1-fitness_norm[i]  # (1-x because high fitness is bad)\n",
    "    )\n",
    "    \n",
    "    #ax.text(x=len(sim_l[i]), y=sim_l[i][-1], s=f\"Fitness {round(fitness_l[i])}\", fontsize=8)\n",
    "    #ax.text(x=len(sim_l[i]), y=sim_l[i][-1], s=f\"P{df.index[sample_idx[i]]}, F{round(fitness_l[i])}\", fontsize=8)\n",
    "ax.plot(x, obs_l[0], label=\"Observations\")\n",
    "ax.plot(x, OpenCLRunner.get_cumulative_new_infections(summaries0), label=\"Initial sim\")\n",
    "ax.legend()\n",
    "#plot_summaries(summaries=summaries_l[0], plot_type=\"error_bars\", observations=OBSERVATIONS)\n",
    "\n",
    "del _fitness, fitness_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the kde of the sample results (a bit like the posterior?). See the [pygam documentation](https://pygam.readthedocs.io/en/latest/notebooks/tour_of_pygam.html) for the GAM code to do this.\n",
    "\n",
    "_The prediction intervals clearly aren't working_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two long arrays with every result from every particle\n",
    "x = list(range(len(sim_l[0])))  # List of iteration numbers\n",
    "X = []\n",
    "for _iter in x * len(summaries_l):  # One sequence of iterations (0-100) for each particle\n",
    "    X.append([_iter]) # (The x list is odd because every element in the list needs to be a 1-element list)\n",
    "X = np.array(X)\n",
    "y = []\n",
    "for i in range(len(summaries_l)):\n",
    "    y += list(OpenCLRunner.get_cumulative_new_infections(summaries_l[i]))\n",
    "y = np.array(y)\n",
    "\n",
    "# Generate the GAM\n",
    "gam = LinearGAM( n_splines=250)\n",
    "#gam = LinearGAM( s(0, n_splines=250) )  # Linear GAM with a spline function on feature 0\n",
    "gam.gridsearch(X, y)\n",
    "#XX = gam.generate_X_grid(term=0, n=len(X))\n",
    "XX = gam.generate_X_grid(term=0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "\n",
    "ax.plot(XX, gam.predict(XX), 'r--')\n",
    "ax.plot(XX, gam.prediction_intervals(XX, width=.95), color='b', ls='--')\n",
    "\n",
    "#pdep, confi = gam.partial_dependence(term=0, width=.95)\n",
    "#ax.plot(XX, pdep)\n",
    "#ax.plot(XX, confi, c='r', ls='--')\n",
    "\n",
    "ax.plot(x, obs_l[0], label=\"Observations\")\n",
    "ax.plot(x, OpenCLRunner.get_cumulative_new_infections(summaries0), label=\"Initial sim\")\n",
    "#plt.scatter(X, y, facecolor='gray', edgecolors='none')\n",
    "ax.legend()\n",
    "#plt.scatter(X, y, facecolor='gray', edgecolors='none')\n",
    "ax.set_title('95% prediction interval');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a KDE plot with a logarithmic colour scale.\n",
    "\n",
    "_Looks like the distribution is multi-model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,7))\n",
    "\n",
    "h = ax.hist2d(x=[x[0] for x in X], y=y, bins=int(len(x)/5),\n",
    "         norm=LogNorm())\n",
    "\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Cumulative cases\")\n",
    "\n",
    "ax.plot(x, obs_l[0], label=\"Observations\")\n",
    "ax.plot(x, OpenCLRunner.get_cumulative_new_infections(summaries0), label=\"Initial sim\")\n",
    "#plt.scatter(X, y, facecolor='gray', edgecolors='none')\n",
    "ax.legend()\n",
    "fig.colorbar(h[3], ax=ax)\n",
    "#plt.scatter(X, y, facecolor='gray', edgecolors='none')\n",
    "ax.set_title('Density plot of results posterior');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ABC Posterior (B) - Find the Mode(s)\n",
    "\n",
    "_I can't work out how to find the modes (basically I think I need the largest value of the `kde`?) so instead just choose the parameter values from the best sample_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the 'optimal' parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load samples if needed\n",
    "#fitness_l, sim_l, obs_l, out_params_l, summaries_l = pickle_samples(\"load\")\n",
    "\n",
    "# Find the best parameters\n",
    "best_model_idx = np.argmin(fitness_l)\n",
    "best_params = out_calibrated_params_l[best_model_idx]\n",
    "# Sanity check, the calibrated param should be the same as the one in the params object\n",
    "assert np.isclose(out_calibrated_params_l[best_model_idx]['presymptomatic'],\n",
    "                  out_params_l[best_model_idx].individual_hazard_multipliers[0])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how those parameters relate to the marginal posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,int(len(priors)/2), figsize=(12,8))\n",
    "\n",
    "for i, param in enumerate(priors.keys()):\n",
    "    ax = axes.flat[i]\n",
    "    df, w = history.get_distribution(m=0, t=history.max_t)\n",
    "    pyabc.visualization.plot_kde_1d(df, w, x=param, ax=ax, \n",
    "            label=f\"{param} PDF t={t}\", \n",
    "            alpha=1.0 if t==0 else float(t)/history.max_t, # Make earlier populations transparent\n",
    "            color= \"black\" if t==history.max_t else None # Make the last one black\n",
    "        )\n",
    "    ax.legend()\n",
    "    ax.axvline(x=best_params[param], color=\"grey\", linestyle=\"dashed\")\n",
    "    ax.text(x=best_params[param], y=0.9*ax.get_ylim()[1], s=str(round(best_params[param],3)), fontsize=12)\n",
    "    ax.set_title(f\"{param}\")\n",
    "fig.suptitle(\"Optimal parameter values\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model with those parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenCLRunner.update(store_detailed_counts=True)  # Temporarily output age breakdowns\n",
    "(fitness1, sim1, obs1, out_params1, summaries1) = OpenCLRunner.run_model_with_params_abc(\n",
    "    best_params, return_full_details=True)\n",
    "OpenCLRunner.update(store_detailed_counts=STORE_DETAILED_COUNTS)\n",
    "\n",
    "# Check the model returns the observations correctly (should be same as initial, default model)\n",
    "np.array_equal(obs0, obs1)\n",
    "\n",
    "# Print the fitness and plot the different disease counts\n",
    "print(f\"Fitness: {fitness1}\")\n",
    "#print(pd.DataFrame({\"sim\":sim, \"real_obs1\":obs}))\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "x = range(len(sim1))\n",
    "ax.plot(x, OpenCLRunner.get_cumulative_new_infections(summaries0), label=\"sim0\")\n",
    "ax.plot(x, OpenCLRunner.get_cumulative_new_infections(summaries1), label=\"sim1\")\n",
    "ax.plot(x, obs1, label=\"obs\")\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial analysis of the posterior\n",
    "\n",
    "We've seen how the aggregate, cumulative disease count varies, but how do the results vary over space?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the distribtion of explosed people in the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(summaries1)\n",
    "disease_status = \"exposed\"\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=int(N/2) if (N % 2) == 0 else int(N/2)+1,\n",
    "                    figsize=(12,8))\n",
    "\n",
    "for i in range(N):\n",
    "    #idx = indices[i]\n",
    "    ax = axes.flat[i]\n",
    "    plot_msoa_choropleth(devon_msoa_shapes, summaries1[i], disease_status, 99, ax=ax)\n",
    "    ax.set_title(f\"Run {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XXXX HERE there is too much spatial variation? Might need to reduce impact of workplace interactions. Or maybe this is interesting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5189e42352497b0ca2f9957f845b08361f94c6e988b05d058a7abb809ed76937"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
